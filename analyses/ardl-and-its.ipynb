{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f88b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from utils import *\n",
    "from analysis_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Necessary data (both weekly and monthly):\n",
    "- Shocks\n",
    "- Confounds\n",
    "- Trends outcomes\n",
    "- KSU\n",
    "\"\"\"\n",
    "\n",
    "prefix = '../data/prepared/merged/'\n",
    "units = 'weeks'\n",
    "\n",
    "if units == 'weeks':\n",
    "    bonf_denom = 7\n",
    "elif units == 'months':\n",
    "    bonf_denom = 6\n",
    "else:\n",
    "    assert 0\n",
    "\n",
    "do_controls = False\n",
    "do_primary = True\n",
    "\n",
    "# Run primary analyses\n",
    "pval_thresh_1 = 0.05/bonf_denom\n",
    "\n",
    "month_tests = 6*15*3 #intvns * outcomes * [assoc, contemp, lagged]\n",
    "week_tests = 7*12*3 # intvns * outcomes * [assoc, contemp lagged]\n",
    "\n",
    "all_tests = month_tests + week_tests\n",
    "\n",
    "pval_thresh_2 = 0.05/all_tests#(month_tests + week_tests)\n",
    "\n",
    "# Settings for non-bin models\n",
    "do_differencing = True\n",
    "include_time = False\n",
    "\n",
    "# Settings for both\n",
    "add_L = True\n",
    "normalize = True\n",
    "include_month = True\n",
    "\n",
    "# Settings for bin models\n",
    "do_differencing_bin = False\n",
    "include_time_bin = True\n",
    "duration_months = 5\n",
    "bin_slope = True\n",
    "\n",
    "models_to_run = ['assoc', 'contemp', 'lagged']\n",
    "\n",
    "# KSU params\n",
    "ksu_lag = None\n",
    "\n",
    "verbose=True\n",
    "\n",
    "\n",
    "netflix_release_dates = {'tgc': [2019, 10, 16], 'fok': [2011, 5, 6], 'okja': [2017, 6, 28],\n",
    "                'wth': [2017, 6, 16], 'cowspiracy': [2015, 9, 15], 'owth': [2017, 6, 16], \n",
    "                         'yawye': [2024, 1, 1]}\n",
    "\n",
    "restrictions = {'StewartMilk': ['cowspiracy', 'wth', 'okja', 'owth', 'all_docs'], \n",
    "                'StewartPBMilk': ['cowspiracy', 'wth', 'okja', 'owth', 'all_docs'],\n",
    "                'Zhao': ['wth', 'okja', 'owth', 'tgc', 'all_docs']}\n",
    "\n",
    "binary_analysis_dct = {'Zhao': ['owth', 'wth', 'okja', 'tgc'], 'NeuhoferLusk': ['tgc'],\n",
    "                      'StewartMilk': ['cowspiracy', 'owth', 'wth', 'okja'], \n",
    "                       'StewartPBMilk': ['cowspiracy', 'owth', 'wth', 'okja']}\n",
    "\n",
    "normalized = pd.read_csv(prefix + 'merged_' + units + '.csv')\n",
    "\n",
    "if do_controls:\n",
    "    normalized_controls = pd.read_csv(prefix + 'merged_controls_' + units + '.csv')\n",
    "\n",
    "assert units in ['weeks', 'months', 'days']\n",
    "assert len(set(units) & set(prefix)) !=0 \n",
    "\n",
    "#Lists\n",
    "common = ['ds', 'Time', 'Month']\n",
    "\n",
    "all_docs = ['tgc', 'wth', 'fok', 'cowspiracy', 'okja', 'yawye']\n",
    "all_ts_albums = ['reputation', 'ts_1989', 'lover', 'speak_now', 'red']\n",
    "all_climate = ['climate', 'climate_change', 'sustainability']\n",
    "all_ts_outcomes = ['taylor_swift', 'taylor_swift_lyrics', 'taylor_swift_songs',\n",
    "                  'taylor_swift_tour', 'taylor_swift_album']\n",
    "\n",
    "all_drake_albums = ['scorpion', 'take_care', 'views', 'nwts', 'tml']\n",
    "all_drake_outcomes = ['drake', 'drake_lyrics', 'drake_songs', 'drake_tour', 'drake_album']\n",
    "\n",
    "\n",
    "if units == 'months':\n",
    "    all_primary_outcomes = ['plant_based_plus_plant_based', 'vegan', 'vegetarian', \n",
    "                           'ksu_beef', 'ksu_pork', 'ksu_chicken']\n",
    "    \n",
    "    all_primary_outcomes += ['StewartMilk',  \n",
    "                            'StewartPBMilk', 'Zhao'] \n",
    "\n",
    "    all_secondary_outcomes = ['vegan_informative', 'vegetarian_informative',\n",
    "           'plant_based_informative', 'vegan_behavior', 'vegetarian_behavior',\n",
    "           'plant_based_behavior']\n",
    "    \n",
    "    all_outcomes = all_primary_outcomes + all_secondary_outcomes \n",
    "    \n",
    "    intvns = ['fok', 'cowspiracy', 'owth', 'tgc', 'yawye', 'all_docs']\n",
    "    \n",
    "elif units == 'weeks':\n",
    "    all_primary_outcomes = ['plant_based_plus_plant_based','vegan', 'vegetarian',\n",
    "                            'StewartMilk', \n",
    "                            'StewartPBMilk',\n",
    "                            'Zhao']   \n",
    "\n",
    "    all_secondary_outcomes = ['vegan_informative', 'vegetarian_informative',\n",
    "           'plant_based_informative', 'vegan_behavior', 'vegetarian_behavior',\n",
    "           'plant_based_behavior']\n",
    "    \n",
    "    all_outcomes = all_primary_outcomes + all_secondary_outcomes\n",
    "    intvns = ['fok', 'cowspiracy', 'okja', 'wth', 'tgc', 'yawye', 'all_docs'] #'okja', 'wth'        \n",
    "    \n",
    "else:\n",
    "    assert 0\n",
    "        \n",
    "# Outcomes, interventions, and models to run\n",
    "test_outcomes = all_outcomes\n",
    "test_intvns =  intvns\n",
    "\n",
    "models = ['assoc', 'contemp', 'lagged', 'bin']\n",
    "for model in models_to_run:\n",
    "    assert model in models\n",
    "\n",
    "#run_name = 'bin_{num}months_slope{val}'.format(num=duration_months, val=bin_slope)\n",
    "\n",
    "run_name = 'test'#'ksu_lag_' + str(ksu_lag) + 'assoc_contemp_lagged_2024'\n",
    "\n",
    "print(run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bbfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift KSU\n",
    "if ksu_lag:\n",
    "    normalized['ksu_chicken'] = normalized['ksu_chicken'].shift(-1*ksu_lag)\n",
    "    normalized['ksu_pork'] = normalized['ksu_pork'].shift(-1*ksu_lag)\n",
    "    normalized['ksu_beef'] = normalized['ksu_beef'].shift(-1*ksu_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037438d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge for controls\n",
    "# 522\n",
    "if do_controls:\n",
    "    merged_for_controls = normalized.merge(normalized_controls, on=common)\n",
    "    run_controls(merged_for_controls.copy(), pval_thresh=0.05, PS=True, PS_logistic=False, \n",
    "                 fit_method='GLSAR', model='lagged', bonf_denom=522,\n",
    "                    add_L=False, difference=True, normalize=True, include_month=True,\n",
    "                include_time=False, verbose=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    run_controls_binary(merged_for_controls.copy(), PS=False, PS_logistic=False, fit_method='GLSAR', model='bin', bonf_denom=5,\n",
    "                 add_L=True,\n",
    "                duration_months=12,\n",
    "                difference=False, verbose=False)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfs for heatmaps\n",
    "heat_dfs = {}\n",
    "annot_dfs = {}\n",
    "\n",
    "intvn_map = {'fok': 'FOK', 'cowspiracy': 'Cowspiracy', 'wth': 'WTH', 'okja': \"Okja\", 'owth': \n",
    "             'Okja/WTH', 'tgc': 'TGC', 'yawye': 'YAWYE', 'all_docs': 'All'}\n",
    "outcome_map = {'vegan': \"Searches: `Vegan'\", 'vegetarian': \"Searches: `Vegetarian'\", \n",
    "               'plant_based_plus_plant_based': \"Searches: `Plant based'\",\n",
    "              'ksu_beef': 'Beef Demand',\n",
    "              'ksu_chicken': 'Chicken Demand',\n",
    "              'ksu_pork': 'Pork Demand',\n",
    "              'Zhao': 'Zhao',\n",
    "              'NeuhoferLusk': 'NeuhoferLusk',\n",
    "              'StewartPBMilk': 'StewartPBMilk',\n",
    "              'StewartMilk': 'StewartMilk',\n",
    "               'vegan_informative': \"Searches: `Vegan', Informative\",\n",
    "           'vegetarian_informative': \"Searches: `Vegetarian', Informative\", \n",
    "               'plant_based_informative': \"Searches: `Plant based', Informative\", \n",
    "               'vegan_behavior': \"Searches: `Vegan', Behavior\",\n",
    "           'vegetarian_behavior': \"Searches: `Vegetarian', Behavior\", \n",
    "               'plant_based_behavior': \"Searches: `Plant based', Behavior\"}\n",
    "\n",
    "coef_dcts = {}\n",
    "annot_dcts = {}\n",
    "pval_dcts = {}\n",
    "se_dcts = {}\n",
    "\n",
    "for model in models:\n",
    "    coef_dcts[model] = {}\n",
    "    annot_dcts[model] = {}\n",
    "    pval_dcts[model] = {}\n",
    "    se_dcts[model] = {}\n",
    "\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for intvn in intvns:\n",
    "        coef_dcts[model][intvn_map[intvn]] = {}\n",
    "        annot_dcts[model][intvn_map[intvn]] = {}\n",
    "        pval_dcts[model][intvn_map[intvn]] = {}\n",
    "        se_dcts[model][intvn_map[intvn]] = {}\n",
    "        for outcome in all_outcomes:\n",
    "            coef_dcts[model][intvn_map[intvn]][outcome_map[outcome]] = np.nan\n",
    "            annot_dcts[model][intvn_map[intvn]][outcome_map[outcome]] = ''\n",
    "            pval_dcts[model][intvn_map[intvn]][outcome_map[outcome]] = np.nan\n",
    "            se_dcts[model][intvn_map[intvn]][outcome_map[outcome]] = np.nan\n",
    "    heat_dfs[model] = pd.DataFrame(coef_dcts[model])\n",
    "    annot_dfs[model] = pd.DataFrame(annot_dcts[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(pval, thresh1, thresh2, sens_pvals=None):\n",
    "    if pval < thresh2:\n",
    "        if sens_pvals:\n",
    "            for sens_pval in sens_pvals:\n",
    "                if sens_pval >= thresh2:\n",
    "                    return '**'\n",
    "            return '***'\n",
    "        else:\n",
    "            return '**'\n",
    "    elif pval < thresh1:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104d005-7806-4c2e-a94e-fa8444f26ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_primary:\n",
    "    #for outcome in ['ksu_beef', 'ksu_pork', 'ksu_chicken']:\n",
    "    sens_add_L = not add_L\n",
    "    for outcome in test_outcomes:\n",
    "        for intvn in test_intvns:\n",
    "            if outcome in restrictions and intvn not in restrictions[outcome]:\n",
    "                continue\n",
    "            \n",
    "            print('intvn: ', intvn)\n",
    "            \n",
    "            if 'assoc' in models_to_run:\n",
    "                print('Association: ')\n",
    "                assoc_pval, assoc_beta, assoc_se = run_primary_analyses(normalized.copy(), intvn, outcome, PS=False, \n",
    "                                     fit_method='GLSAR', model='assoc', \n",
    "                                     add_L=False, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=False, normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                print('beta, pval: ', assoc_beta, assoc_pval)\n",
    "                coef_dcts['assoc'][intvn_map[intvn]][outcome_map[outcome]] = assoc_beta\n",
    "                annot_dcts['assoc'][intvn_map[intvn]][outcome_map[outcome]] = eval_pval(assoc_pval, pval_thresh_1, pval_thresh_2)\n",
    "                se_dcts['assoc'][intvn_map[intvn]][outcome_map[outcome]] = assoc_se\n",
    "                pval_dcts['assoc'][intvn_map[intvn]][outcome_map[outcome]] = assoc_pval\n",
    "            \n",
    "            if 'contemp' in models_to_run:\n",
    "                print('Contemporaneous: ')\n",
    "                contemp_pval, contemp_beta, contemp_se = run_primary_analyses(normalized.copy(), intvn, outcome, PS=True, \n",
    "                                    fit_method='GLSAR', model='contemp', \n",
    "                                     add_L=add_L, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=include_month, normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                contemp_pval_sens1, _, _ = run_primary_analyses(normalized.copy(), intvn, outcome, PS=True, \n",
    "                                    fit_method='GLSAR', model='contemp', \n",
    "                                     add_L=sens_add_L, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=include_month, normalize=normalize, verbose=verbose, units=units)            \n",
    "\n",
    "                contemp_pval_sens2, _, _ = run_primary_analyses(normalized.copy(), intvn, outcome, PS=False, \n",
    "                                    fit_method='GLSAR', model='contemp', \n",
    "                                     add_L=add_L, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=include_month, normalize=normalize, verbose=verbose, units=units)   \n",
    "\n",
    "                print('beta, pval: ', contemp_beta, contemp_pval)\n",
    "                coef_dcts['contemp'][intvn_map[intvn]][outcome_map[outcome]] = contemp_beta\n",
    "                se_dcts['contemp'][intvn_map[intvn]][outcome_map[outcome]] = contemp_se\n",
    "                contemp_pvals_sens = [contemp_pval_sens1, contemp_pval_sens2]\n",
    "                print('contemp_pvals_sens: ', contemp_pvals_sens)\n",
    "                annot_dcts['contemp'][intvn_map[intvn]][outcome_map[outcome]] = eval_pval(contemp_pval, pval_thresh_1, pval_thresh_2, contemp_pvals_sens)\n",
    "                pval_dcts['contemp'][intvn_map[intvn]][outcome_map[outcome]] = contemp_pval\n",
    "            \n",
    "            if 'lagged' in models_to_run:\n",
    "                print('Lagged: ')\n",
    "                lagged_pval, lagged_beta, lagged_se = run_primary_analyses(normalized.copy(), intvn, outcome, PS=True, \n",
    "                                     fit_method='GLSAR', model='lagged', \n",
    "                                     add_L=add_L, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=include_month, normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                lagged_pval_sens1, _, _ = run_primary_analyses(normalized.copy(), intvn, outcome, PS=True, \n",
    "                                     fit_method='GLSAR', model='lagged', \n",
    "                                     add_L=sens_add_L, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=include_month, normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                lagged_pval_sens2, _, _ = run_primary_analyses(normalized.copy(), intvn, outcome, PS=False, \n",
    "                                     fit_method='GLSAR', model='lagged', \n",
    "                                     add_L=add_L, difference=do_differencing, include_time=include_time, \n",
    "                                     include_month=include_month, normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                print('beta, pval: ', lagged_beta, lagged_pval)\n",
    "                coef_dcts['lagged'][intvn_map[intvn]][outcome_map[outcome]] = lagged_beta\n",
    "                se_dcts['lagged'][intvn_map[intvn]][outcome_map[outcome]] = lagged_se\n",
    "                lagged_pvals_sens = [lagged_pval_sens1, lagged_pval_sens2]\n",
    "                print('lagged_pvals_sens: ', lagged_pvals_sens)\n",
    "                annot_dcts['lagged'][intvn_map[intvn]][outcome_map[outcome]] = eval_pval(lagged_pval, pval_thresh_1, pval_thresh_2, lagged_pvals_sens)\n",
    "                pval_dcts['lagged'][intvn_map[intvn]][outcome_map[outcome]] = lagged_pval\n",
    "\n",
    "            print('Bin: ')\n",
    "            if 'bin' in models_to_run:\n",
    "                if (outcome in binary_analysis_dct) and (intvn not in binary_analysis_dct[outcome]):\n",
    "                    continue\n",
    "\n",
    "                if intvn == 'all_docs':\n",
    "                    continue\n",
    "                    \n",
    "                bin_pval, bin_beta, bin_se = run_primary_analyses(normalized.copy(), intvn, outcome, PS=False, \n",
    "                                                          PS_logistic=False,\n",
    "                                     fit_method='GLSAR', model='bin', \n",
    "                                     add_L=add_L, difference=do_differencing_bin, include_time=include_time_bin, \n",
    "                                     include_month=include_month, duration_months=duration_months, \n",
    "                                                          normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                bin_pval_sens1, _, _ = run_primary_analyses(normalized.copy(), intvn, outcome, PS=False,\n",
    "                                                   PS_logistic=False,\n",
    "                                     fit_method='GLSAR', model='bin', \n",
    "                                     add_L=sens_add_L, difference=do_differencing_bin, include_time=include_time_bin, \n",
    "                                     include_month=include_month, duration_months=duration_months, \n",
    "                                                            normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                bin_pval_sens2, _, _ = run_primary_analyses(normalized.copy(), intvn, outcome, PS=False, \n",
    "                                    PS_logistic=False,\n",
    "                                     fit_method='GLSAR', model='bin', \n",
    "                                     add_L=add_L, difference=do_differencing_bin, include_time=include_time_bin, \n",
    "                                     include_month=include_month, duration_months=duration_months, \n",
    "                                                            normalize=normalize, verbose=verbose, units=units)\n",
    "\n",
    "                print('beta, pval: ', bin_beta, bin_pval)            \n",
    "                    \n",
    "                bin_pvals_sens = [bin_pval_sens1, bin_pval_sens2]\n",
    "                coef_dcts['bin'][intvn_map[intvn]][outcome_map[outcome]] = bin_beta\n",
    "                se_dcts['bin'][intvn_map[intvn]][outcome_map[outcome]] = bin_se\n",
    "                annot_dcts['bin'][intvn_map[intvn]][outcome_map[outcome]] = eval_pval(bin_pval, pval_thresh_1, pval_thresh_2, bin_pvals_sens)\n",
    "                pval_dcts['bin'][intvn_map[intvn]][outcome_map[outcome]] = bin_pval\n",
    "                print('bin_pvals_sens: ', bin_pvals_sens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ffdd7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "min_val = np.inf\n",
    "max_val = -np.inf\n",
    "for model in ['assoc', 'contemp', 'lagged', 'bin']:\n",
    "    heat_dfs[model] = pd.DataFrame(coef_dcts[model])\n",
    "    annot_dfs[model] = pd.DataFrame(annot_dcts[model])\n",
    "    \n",
    "    if heat_dfs[model].min().min() < min_val:\n",
    "        min_val = heat_dfs[model].min().min()\n",
    "    if heat_dfs[model].max().max() > max_val:\n",
    "        max_val = heat_dfs[model].max().max()\n",
    "    \n",
    "\n",
    "model_maps = {'assoc': 'Association', 'contemp': 'Contemporaneous', 'lagged': 'Lagged',\n",
    "             'bin': 'Binary ({d} Months)'.format(d=duration_months)}\n",
    "    \n",
    "for model in ['assoc', 'contemp', 'lagged', 'bin']:    \n",
    "    plt.figure(figsize=(8, 6))  # Optional: Adjusts the size of the figure\n",
    "    cmap = sns.diverging_palette(h_neg=130, h_pos=10, s=99, l=55, sep=3, as_cmap=True)\n",
    "\n",
    "    ax = sns.heatmap(heat_dfs[model], annot=annot_dfs[model], center=0, fmt='s',\n",
    "                     cmap = cmap,\n",
    "                    annot_kws={\"size\": 25}, vmin=min_val, vmax=max_val, yticklabels=True, cbar=True)  # 'annot' annotates the boxes with the data values\n",
    "\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "    # Display the heatmap\n",
    "    plt.title(model_maps[model])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_se_df = pd.DataFrame(se_dcts['assoc'])\n",
    "assoc_coef_df = pd.DataFrame(coef_dcts['assoc'])\n",
    "assoc_pval_df = pd.DataFrame(pval_dcts['assoc'])\n",
    "\n",
    "lagged_se_df = pd.DataFrame(se_dcts['lagged'])\n",
    "lagged_coef_df = pd.DataFrame(coef_dcts['lagged'])\n",
    "lagged_pval_df = pd.DataFrame(pval_dcts['lagged'])\n",
    "\n",
    "contemp_se_df = pd.DataFrame(se_dcts['contemp'])\n",
    "contemp_coef_df = pd.DataFrame(coef_dcts['contemp'])\n",
    "contemp_pval_df = pd.DataFrame(pval_dcts['contemp'])\n",
    "\n",
    "bin_se_df = pd.DataFrame(se_dcts['bin'])\n",
    "bin_coef_df = pd.DataFrame(coef_dcts['bin'])\n",
    "bin_pval_df = pd.DataFrame(pval_dcts['bin'])\n",
    "\n",
    "for col in lagged_se_df.columns:\n",
    "    assoc_se_df = assoc_se_df.rename(columns={col:col+'_se'})\n",
    "    assoc_coef_df = assoc_coef_df.rename(columns={col:col+'_pe'})\n",
    "    assoc_pval_df = assoc_pval_df.rename(columns={col:col+'_pval'})\n",
    "    \n",
    "    lagged_se_df = lagged_se_df.rename(columns={col:col+'_se'})\n",
    "    lagged_coef_df = lagged_coef_df.rename(columns={col:col+'_pe'})\n",
    "    lagged_pval_df = lagged_pval_df.rename(columns={col:col+'_pval'})\n",
    "\n",
    "    contemp_se_df = contemp_se_df.rename(columns={col:col+'_se'})\n",
    "    contemp_coef_df = contemp_coef_df.rename(columns={col:col+'_pe'})\n",
    "    contemp_pval_df = contemp_pval_df.rename(columns={col:col+'_pval'})\n",
    "\n",
    "    bin_se_df = bin_se_df.rename(columns={col:col+'_se'})\n",
    "    bin_coef_df = bin_coef_df.rename(columns={col:col+'_pe'})\n",
    "    bin_pval_df = bin_pval_df.rename(columns={col:col+'_pval'})\n",
    "    \n",
    "assoc_df = pd.concat([assoc_se_df, assoc_coef_df, assoc_pval_df], axis=1)\n",
    "lagged_df = pd.concat([lagged_se_df, lagged_coef_df, lagged_pval_df], axis=1)\n",
    "contemp_df = pd.concat([contemp_se_df, contemp_coef_df, contemp_pval_df], axis=1)\n",
    "bin_df = pd.concat([bin_se_df, bin_coef_df, bin_pval_df], axis=1)\n",
    "\n",
    "assoc_df.index.name = 'Outcome'\n",
    "lagged_df.index.name = 'Outcome'\n",
    "contemp_df.index.name = 'Outcome'\n",
    "bin_df.index.name = 'Outcome'\n",
    "\n",
    "lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa253fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True \n",
    "if save:\n",
    "    prefix = '../results/' + run_name + '_' + units + '_' + str(datetime.now()).replace(' ', '_').replace(':', '_') + '/'\n",
    "    os.makedirs(prefix)\n",
    "    assoc_df.to_csv(prefix + 'assoc_df_{u}_all_primary.csv'.format(u=units))    \n",
    "    lagged_df.to_csv(prefix + 'lagged_df_{u}_all_primary.csv'.format(u=units))\n",
    "    contemp_df.to_csv(prefix + 'contemp_df_{u}_all_primary.csv'.format(u=units))\n",
    "    bin_df.to_csv(prefix + 'bin_df_{u}_all_primary.csv'.format(u=units))\n",
    "    \n",
    "    annot_dfs['assoc'].to_csv(prefix + 'annot_assoc_df_{u}_all_primary.csv'.format(u=units))\n",
    "    annot_dfs['contemp'].to_csv(prefix + 'annot_contemp_df_{u}_all_primary.csv'.format(u=units))\n",
    "    annot_dfs['lagged'].to_csv(prefix + 'annot_lagged_df_{u}_all_primary.csv'.format(u=units))\n",
    "    annot_dfs['bin'].to_csv(prefix + 'annot_bin_df_{u}_all_primary.csv'.format(u=units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
